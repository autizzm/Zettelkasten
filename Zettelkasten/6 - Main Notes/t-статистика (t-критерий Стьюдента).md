
01-10-2025 18:38

Status: #baby 

Tags: [[ТВиМС]]

---
# t-статистика

Фактически t-распределение - это распределение Стьюдента.

А t-статистика -  это название для всех тех коэффициентов и показателей («любой функционал от данных, который при выполнении ​ имеет t-распределение (распределение Стьюдента)»).

(Короче, как и статистика Хи квадрат)



#### **Общая форма t-статистики**

Все эти формулы можно свести к обобщённому виду:

### $t = \frac{\text{оценка} - \text{гипотеза}}{\text{стандартная ошибка оценки}}$​

- Числитель отражает, насколько оценка отклоняется от предполагаемого значения.
    
- Знаменатель учитывает дисперсию (неопределённость) оценки.
    
- Подразумевается, что при **$H_0$​** эта величина распределена по закону Стьюдента с определённым числом степеней свободы.

---
##### **Что проверяет:**

 - значимости корреляции (коэффициент регрессии)
 - гипотезы о среднем (выборочное среднее и матожидание)

> [!note]
> t-статистика - БЕЗРАЗМЕРНАЯ величина
> 
> (не имеет единиц измерения.)

---
## **t-статистика для коэффициента корреляции:**

#### $H_0: \rho = 0 \quad \text{(корреляции нет)}$
#### $H_1: \rho \ne 0 \quad \text{   (корреляция есть)}$   

Для **выборочного коэффициента корреляции** $r$ при объёме выборки $n$ статистика:

### $t = \frac{r \sqrt{n-2}}{\sqrt{1-r^2}}$

- При верной $H_0$​, эта статистика имеет распределение Стьюдента с $n-2$ степенями свободы.
    
- Чем больше $|t|$, тем значимее корреляция.

> [!note]
> При полной линейной зависимости:
> ### $\sqrt{1 - r^2} = 0 \text{ -> } \text{t-statistics} = \text{NA}$

---
## **t-статистика для проверки [[Гипотезы о среднем|гипотез о среднем]]:**

#### $H_0: \mu = 0 \quad \text{(распределение является нормальным: ) N(0,1)}$
#### $H_1: \mu \ne 0 \quad \text{   (распределение не является нормальным)}$   
### $t = \frac{\bar{x} - \mu}{S_x/\sqrt{n}}$


---

## **t-статистика для проверки качества коэффициентов линейной регрессии**

Используется для сравнения эмпирических коэффициентов регрессии $b_0$ и $b_1$ с некоторыми теоретически ожидаемыми значениями $β_0$ и $β_1$ этих коэффициентов.

### $H_0: b_i = \beta_i \quad \text{vs} \quad H_1: b_i \neq \beta_i$

Формула:

## $t_i = \frac{\tilde{b}_i - \text{в}_{i}}{S_{\tilde b_1}}$

где:
- $\tilde{b}_i$ — оценка коэффициента регрессии,
- $\text{в}_i$ - матожидание оценки параметра
- $S_{\tilde b_1}$ — стандартная ошибка оценки коэффициента.
    

Если при уровне значмости $\alpha$:

## $|T_\text{набл}| = |\frac{\tilde{b}_i - \text{в}_i}{S_{\tilde b_1}}| \ge t_{\frac{\alpha}{2}, n-k}$​​

То нулевая гипотеза $H_0: b_i = \beta_i$ верна (т. е. параметр действительно незначим), то рассчитанная t-статистика для этого коэффициента имеет **распределение Стьюдента с $n - k$ степенями свободы**, где:
- $S_{b_i}$ - [[Стандартная ошибка коэффициентов регрессии|стандартная ошибка коэффициента]] $b_i$
- $n$ — объём выборки,    
- $k$ — количество оцениваемых параметров модели (включая свободный член).


## **t-статистика для проверки гипотез о статистической значимости коэффициентов регрессии** (Частный случай проверки качества, где $\beta_i = 0$)

### $H_0: b_1 =0  \quad vs \quad H_1: b_1 \ne 0$

В этом случае рассматривается **двухсторонняя критическая область** , т.к. выжным является именно отличие от нуля коэффициента регрессии, и он может быть как положительным, так и отрицательным.

Т.к. мы проверяем, что $b_i = 0$, т.е. $\beta_i = 0$:

## $t = \frac{b_1}{S_{b_i}} = \frac{b_i}{\sqrt{S_{b_i}^2}}$

> [!note]
> Для ПЛР более важным является анализ статистической зависимости коэффициента $b_1$, т.к. именно в нём скрыто влияние объясняющей переменной $X$ на зависимую переменную $Y$.


----
#### [[t-статистика (t-критерий Стьюдента) - Flashcards|Link to flashcards]]



---
### References:

- [[Ковариация]]
- [[Парная корреляция (Коэффициент Пирсона)]]
- [[Probability (p-value)]]
- [[Гипотезы корреляции]]
- [[t-распределение (Распределение Стьюдента)]]
- [[z-статистика]]