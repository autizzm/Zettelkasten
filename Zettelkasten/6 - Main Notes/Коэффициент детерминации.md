
12-10-2025 13:48

Status: #baby 

Tags: [[ТВиМС]]

---
# Коэффициент детерминации

$TSS = RSS + ESS$

где
- $TSS = \sum_{t=1}^n (y_t - \bar{y})^2$ - total sum square
- $RSS = \sum_{t=1}^n (\tilde{y_t} - \bar{y})^2$ - residual sum square
- $ESS = \sum_{t=1}^n (y_t - \bar{y})^2$ - error sym square



Коэффициент детерминации обозначается **$R^2$** и вычисляется так:

# $R^2 = \frac{RSS}{TSS} = 1 - \frac{ESS}{RSS} = \frac{\sum_{t=1}^n (\tilde{y_t} - \bar{y})^2}{\sum_{t=1}^n (y_t - \bar{y})^2} = 1 - \frac{\sum_{t=1}^{n} (y_i - \tilde{y}_t)^2}{ \sum_{t=1}^{n} (y_t - \bar{y})^2}$

где:
- $\tilde{y_t}$​ — предсказанное значение модели,
- $\bar{y}$ — среднее наблюдаемой переменной $y$.
- $y_t$ — фактическое значение (наблюдение), то на основе чего мы строили модель и получали коэффициенты.

**Смысл:** $R^2$ показывает, какая часть **общей вариации $y$** объясняется моделью.

---

## Интерпретация

- $R^2 = 0$ → модель **ничего не объясняет**, прогноз хуже среднего.
    
- $R^2 = 1$ → модель **объясняет всю вариацию**, идеальное соответствие.
    
- $0 < R^2 < 1$ → доля объяснённой вариации. Например, $R^2 = 0.75$ → модель объясняет 75% вариации $y$.
    

> В статистике иногда $R^2$ называют «коэффициентом объяснённой дисперсии».


---

## Альтернативное выражение через ковариацию (для простой линейной регрессии)

Для простой линейной регрессии $y = b_0 + b_1 x + \varepsilon$ можно выразить через **ковариацию и дисперсии**:
## $R^2 = \frac{S_{xy}^2}{S_x^2 S_y^2} = r_{xy}^2$​

где:

- $S_{xy}$​ — [[Ковариация|ковариация]] $x$ и $y$,
    
- $S_x^2, S_y^2$​ — дисперсии $x$ и $y$,
    
- $r_{xy}$ — **коэффициент корреляции Пирсона**.
    

То есть, для **одного предиктора $x$**, $R^2$ — это **квадрат корреляции между $x$ и $y$**.


---
## Скорректированный коэффициент детерминации

(с учётом степеней свободы)


1. Для **множественной регрессии** с $k > 1$ предикторами  $R^2$ всегда увеличивается при добавлении новых переменных. Поэтому используют **скорректированный $R^2$** ($R^2_\text{adj}$, который учитывает число предикторов и размер выборки:

### $R^2_\text{adj} = 1 - \frac{RSS/(n-k-1)}{TSS/(n-1)}$

2. Высокое $R^2$ **не всегда означает хорошую модель** — важно смотреть на значимость коэффициентов и остатки.
    
3. $R^2$ не говорит о причинно-следственной связи, только о **линейной согласованности** между предсказанными и фактическими значениями.


----
#### [[Коэффициент детерминации - Flashcards|Link to flashcards]]



---
### References:

