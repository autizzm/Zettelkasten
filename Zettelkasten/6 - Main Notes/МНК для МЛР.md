
14-10-2025 18:36

Status: #baby 

Tags: [[ТВиМС]]

---
# МНК для МЛР

Для применения МНК для МЛР тербуется выполнения [[Классические предпосылки МНК|классических предпосылок МНК ]](включая отстутствие ~={cyan}мультиколлинеарности=~)

#### Эмпирическое уравнение МЛР:

### $Y = b_0 + b_1X_1 + b_2X_2 + \dots + b_mX_m + e$

Здесь
- $b_0, b_1, \dots, b_m$ - оценки теоретических значений $\beta_1, \beta_2, \dots \beta_m$ коэффициентов регрессии
- $e$ - оценка отклонения $\varepsilon$

Для индивидуальных наблюдений:

#### $y_i = b_0 + b_1x_{i1} + b_2x_{i2} + \dots + b_mx_{im} + e_1$

---

### Минимизация отклонений

Отклонение $e_i$ значения $y_i$ зависимой переменной $Y$ от модельного значения $\tilde{y_i}$ рассчитывается по формуле:
### $e_i = y_i - b_0 - b_1x_{i1} - \dots - b_mx_{im}$

Тогда МНК для МЛР:

### $Q = \sum_{i=1}^n e_i^2 = \sum_{i=1}^n (y_i - (b_0 + \sum_{j=1}^m b_jx_{ij}))^2$

Квадратична + ограничена снизу -> имеет мнимум

Условие минимума - все частные производные по $b_j$ равны 0:

![[Pasted image 20251014185247.png]]
![[Pasted image 20251014185300.png]]

Если предпосылки МНК выполняются (в частности, отсутствие ~={cyan}мультиколлинеарности=~) -> система имеет единственное решение.


---

## Расчёт

![[Pasted image 20251014185553.png]]

Здесь 
- $X$ - матрица размера $n \times (m+1)$ т.к. первый столбец заполняется нулями, чтобы свободный член $b_0$ был.

При умножении матрицы $X$ на $B$ по [[Произведение матриц|принципу умножения матриц]] в строке $i$ мы получаем результат (который, если сложить с $e_i$ (путём [[Сумма (разность) матриц|сложения матриц]] $XB+E$ ) будет равен матрице $Y$):
#### $b_0 \cdot 1 + b_1 \cdot x_{i1} + b_2 \cdot x_{i2} + \dots + b_m \cdot x_{im}$

> [!note] 
> Данные наблюдений ПЛР тоже можно представить в матричном виде, только матрица $X$ будет столбцовой (вертикальный вектор) 

### $Y = XB +e$


---
### Минимизация отклонений в матричной форме

### $Q = \sum_{i=1}^n e_i^2; \quad Q \to min$

**Представим в матричной форме:**

1. Чтобы умножить $e$ на себя же, [[Транспонирование матриц|транспонируем]] её:
(получаем произведение вектор-строки $e^T$ на вектор-столбец $e$ -> умножаем по [[Произведение матриц|правилу]])
### $Q = e^T\cdot e = (Y - XB)^T \cdot (Y - XB)$

2. Далее применяем [[Транспонирование матриц#Свойства транспонированных матриц|свойства транспонированных матриц]]:
### $$\begin{aligned}(Y - XB)^T \cdot & (Y - XB) = Y^TY -B^TX^TY - Y^TXB + B^TX^TXB = \\ & = Y^TY - 2B^TX^TY + B^TX^TXB\end{aligned}$$

Необходимым условием экстремума функции $Q$ является равенство нулю её частных производных:
### $\frac{\partial Q}{\partial b_j} = 0 \quad \text{по всем параметрам } b_j, \quad j = 0,1,\dots, m$

 В матричном виде:

### $\frac{\partial Q}{\partial B} = -2 X^TY + 2(X^TX)B$


### Обоснование того, как вязли частную производную:

~={pink}Правила дифференцирования матриц?=~

1. Производная от $Y^TY$ - равна 0.
![[Pasted image 20251015105009.png]]

2. Нахождение производной от $2B^TX^TY$:

![[Pasted image 20251015105035.png]]



3. Нахождение производной от $B^TX^TXB$:
![[Pasted image 20251015101204.png]]
![[Pasted image 20251015101309.png]]


4. Подставляем всё:
![[Pasted image 20251015105512.png]]

---

### Формула нахождения вектора коэффициентов МЛР по МНК:

## $B = (X^TX)^{-1}X^TY$


----
#### [[МНК для МЛР - Flashcards|Link to flashcards]]



---
### References:

- [[Нахождение коэффициентов МЛР по МНК на примере ПЛР]]
- [[Классические предпосылки МНК]]